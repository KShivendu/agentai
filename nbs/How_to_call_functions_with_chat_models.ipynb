{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e67f200",
   "metadata": {},
   "source": [
    "# How to call functions with chat models\n",
    "\n",
    "This notebook covers how to use the Chat Completions API in combination with external functions to extend the capabilities of GPT models.\n",
    "\n",
    "## How to use functions\n",
    "\n",
    "`functions` is an optional parameter in the ChatCompletion API which can be used to provide function specifications. The purpose of this is to enable models to generate outputs which adhere to function input schemas. Note that the API will not actually execute any function calls. It is up to developers to execute function calls using model outputs.\n",
    "\n",
    "If the `functions` parameter is provided then by default the model will decide when it is appropriate to use one of the functions. The API can also be forced to use a specific function by setting the `function_call` parameter to `{\"name\": \"<insert-function-name>\"}`. If a function is used, the output will contain `\"finish_reason\": \"function_call\"` in the response, as well as a `function_call` object that has the name of the function and the generated function arguments.\n",
    "\n",
    "Functions are specified with the following fields:\n",
    "\n",
    "- **Name:** The name of the function.\n",
    "- **Description:** A description of what the function does. The model will use this to decide when to call the function.\n",
    "- **Parameters:** The parameters object contains all of the input fields the function requires. These inputs can be of the following types: String, Number, Boolean, Object, Null, AnyOf. Refer to the [API reference docs](https://platform.openai.com/docs/api-reference/chat) for details.\n",
    "- **Required:** Which of the parameters are required to make a query. The rest will be treated as optional.\n",
    "\n",
    "You can chain function calls by executing the function and passing the output of the function execution directly back to the assistant. This can lead to _infinite loop_ behaviour where the model continues calling functions indefinitely, however guardrails can be put in place to prevent this.\n",
    "\n",
    "## Walkthrough\n",
    "\n",
    "This cookbook takes you through the following workflow:\n",
    "\n",
    "- **Basic concepts:** Creating an example function and getting the API to use it if appropriate.\n",
    "- **Integrating API calls with function execution:** Creating an agent that uses API calls to generate function arguments and then executes the function.\n",
    "- **Using multiple functions:** Allowing multiple functions to be called in sequence before responding to the user.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dab872c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown, Latex\n",
    "import json\n",
    "import openai\n",
    "import os\n",
    "from tenacity import retry, wait_random_exponential, stop_after_attempt\n",
    "import tiktoken\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "GPT_MODEL = \"gpt-3.5-turbo-0613\"\n",
    "EMBEDDING_MODEL = \"text-embedding-ada-002\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69ee6a93",
   "metadata": {},
   "source": [
    "## Utilities\n",
    "\n",
    "First let's define a few utilities for making calls to the Chat Completions API and for maintaining and keeping track of the conversation state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "745ceec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from agentai.api import chat_complete\n",
    "from agentai.conversation import Conversation\n",
    "from agentai.function_parser import function_info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29d4e02b",
   "metadata": {},
   "source": [
    "## Basic concepts\n",
    "\n",
    "Next we'll create a specification for a function called ```get_current_weather```. Later we'll pass this function specification to the API in order to generate function arguments that adhere to the specification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d2e25069",
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "\n",
    "\n",
    "class TemperatureUnit(Enum):\n",
    "    celsius = \"celsius\"\n",
    "    fahrenheit = \"fahrenheit\"\n",
    "\n",
    "\n",
    "@function_info\n",
    "def get_current_weather(location: str, format: TemperatureUnit) -> str:\n",
    "    \"\"\"\n",
    "    Get the current weather\n",
    "\n",
    "    Args:\n",
    "        location (str): The city and state, e.g. San Francisco, CA\n",
    "        format (str): The temperature unit to use. Infer this from the users location.\n",
    "\n",
    "    Returns:\n",
    "        str: The current weather\n",
    "    \"\"\"\n",
    "    # Your function implementation goes here.\n",
    "    return \"\"\n",
    "\n",
    "\n",
    "registered_functions = [get_current_weather]\n",
    "functions = [json.loads(func.json_info) for func in registered_functions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "131d9a33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No response from assistant, trying again\n",
      "No response from assistant, trying again\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'role': 'assistant',\n",
       " 'content': 'In which city would you like to know the current weather?'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation = Conversation()\n",
    "conversation.add_message(\"user\", \"what is the weather like today?\")\n",
    "\n",
    "message = {\"role\": \"assistant\", \"content\": None}\n",
    "chat_response = chat_complete(conversation.conversation_history, functions=functions, model=GPT_MODEL)\n",
    "message = chat_response.json()[\"choices\"][0][\"message\"]\n",
    "while message[\"content\"] is None:\n",
    "    print(\"No response from assistant, trying again\")\n",
    "    chat_response = chat_complete(conversation.conversation_history, functions=functions, model=GPT_MODEL)\n",
    "    message = chat_response.json()[\"choices\"][0][\"message\"]\n",
    "conversation.add_message(message[\"role\"], message[\"content\"])\n",
    "message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ee28e0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'user', 'content': 'what is the weather like today?'},\n",
       " {'role': 'assistant',\n",
       "  'content': 'In which city would you like to know the current weather?'}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.conversation_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "854b6e61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'location': 'Bengaluru, India', 'format': 'celsius'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Once the user provides the required information, the model can generate the function arguments\n",
    "conversation.add_message(\"user\", \"I'm in Bengaluru, India\")\n",
    "chat_response = chat_complete(conversation.conversation_history, functions=functions, model=GPT_MODEL)\n",
    "\n",
    "eval(chat_response.json()[\"choices\"][0][\"message\"][\"function_call\"][\"arguments\"])\n",
    "# chat_response.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4482aee",
   "metadata": {},
   "source": [
    "## Integrating API calls with function execution\n",
    "\n",
    "In our next example, we'll demonstrate how to execute functions whose inputs are model-generated, and use this to implement an agent that can answer questions for us about a database. For simplicity we'll use the [Chinook sample database](https://www.sqlitetutorial.net/sqlite-sample-database/).\n",
    "\n",
    "*Note:* SQL generation use cases are high-risk in a production environment - models can be unreliable when generating consistent SQL syntax. A more reliable way to solve this problem may be to build a query generation API that takes the desired columns as input from the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7654fef",
   "metadata": {},
   "source": [
    "### Pull SQL Database Info\n",
    "\n",
    "First let's define some helpful utility functions to extract data from a SQLite database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "30f6b60e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opened database successfully\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "\n",
    "conn = sqlite3.connect(\"../data/Chinook.db\")\n",
    "print(\"Opened database successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77e6e5ea",
   "metadata": {},
   "source": [
    "Now can use these utility functions to extract a representation of the database schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0c0104cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from agentai.sqlite_utils import DBUtils\n",
    "\n",
    "database_schema_dict = DBUtils(conn).get_database_info()\n",
    "database_schema_string = \"\\n\".join(\n",
    "    [f\"Table: {table['table_name']}\\nColumns: {', '.join(table['column_names'])}\" for table in database_schema_dict]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1f05b9e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table: Album\n",
      "Columns: AlbumId, Title, ArtistId\n",
      "Table: Artist\n",
      "Columns: ArtistId, Name\n",
      "Table: Customer\n",
      "Columns: CustomerId, FirstName, LastName, Company, Address, City, State, Country, PostalCode, Phone, Fax, Email, SupportRepId\n",
      "Table: Employee\n",
      "Columns: EmployeeId, LastName, FirstName, Title, ReportsTo, BirthDate, HireDate, Address, City, State, Country, PostalCode, Phone, Fax, Email\n",
      "Table: Genre\n",
      "Columns: GenreId, Name\n",
      "Table: Invoice\n",
      "Columns: InvoiceId, CustomerId, InvoiceDate, BillingAddress, BillingCity, BillingState, BillingCountry, BillingPostalCode, Total\n",
      "Table: InvoiceLine\n",
      "Columns: InvoiceLineId, InvoiceId, TrackId, UnitPrice, Quantity\n",
      "Table: MediaType\n",
      "Columns: MediaTypeId, Name\n",
      "Table: Playlist\n",
      "Columns: PlaylistId, Name\n",
      "Table: PlaylistTrack\n",
      "Columns: PlaylistId, TrackId\n",
      "Table: Track\n",
      "Columns: TrackId, Name, AlbumId, MediaTypeId, GenreId, Composer, Milliseconds, Bytes, UnitPrice\n"
     ]
    }
   ],
   "source": [
    "print(database_schema_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae73c9ee",
   "metadata": {},
   "source": [
    "As before, we'll define a function specification for the function we'd like the API to generate arguments for. Notice that we are inserting the database schema into the function specification. This will be important for the model to know about."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0258813a",
   "metadata": {},
   "outputs": [],
   "source": [
    "@function_info\n",
    "def ask_database(query: str) -> str:\n",
    "    \"\"\"\n",
    "    Use this function to answer user questions about music. Input should be a fully formed SQL query.\n",
    "\n",
    "    Args:\n",
    "        query (str):SQL query extracting info to answer the user's question.\n",
    "                    SQL should be written using this database schema:\n",
    "                    Table: Album\n",
    "                    Columns: AlbumId, Title, ArtistId\n",
    "                    Table: Artist\n",
    "                    Columns: ArtistId, Name\n",
    "                    Table: Customer\n",
    "                    Columns: CustomerId, FirstName, LastName, Company, Address, City, State, Country, PostalCode, Phone, Fax, Email, SupportRepId\n",
    "                    Table: Employee\n",
    "                    Columns: EmployeeId, LastName, FirstName, Title, ReportsTo, BirthDate, HireDate, Address, City, State, Country, PostalCode, Phone, Fax, Email\n",
    "                    Table: Genre\n",
    "                    Columns: GenreId, Name\n",
    "                    Table: Invoice\n",
    "                    Columns: InvoiceId, CustomerId, InvoiceDate, BillingAddress, BillingCity, BillingState, BillingCountry, BillingPostalCode, Total\n",
    "                    Table: InvoiceLine\n",
    "                    Columns: InvoiceLineId, InvoiceId, TrackId, UnitPrice, Quantity\n",
    "                    Table: MediaType\n",
    "                    Columns: MediaTypeId, Name\n",
    "                    Table: Playlist\n",
    "                    Columns: PlaylistId, Name\n",
    "                    Table: PlaylistTrack\n",
    "                    Columns: PlaylistId, TrackId\n",
    "                    Table: Track\n",
    "                    Columns: TrackId, Name, AlbumId, MediaTypeId, GenreId, Composer, Milliseconds, Bytes, UnitPrice\n",
    "\n",
    "                    IMPORTANT: Please return a fixed SQL in PLAIN TEXT.\n",
    "                    Your response should consist of ONLY the SQL query.\n",
    "\n",
    "    Returns:\n",
    "        str: _description_\n",
    "    \"\"\"\n",
    "    try:\n",
    "        results = conn.execute(query).fetchall()\n",
    "        return results\n",
    "    except Exception as e:\n",
    "        raise Exception(f\"SQL error: {e}\")\n",
    "\n",
    "\n",
    "agentai_functions = [json.loads(func.json_info) for func in [ask_database]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da08c121",
   "metadata": {},
   "source": [
    "### SQL execution\n",
    "\n",
    "Now let's implement the function that the agent will use to query the database. We also need to implement utilities to integrate the calls to the Chat Completions API with the function it is calling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5f845a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "from agentai.api import chat_complete_execute_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "38c55083",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_system_message = \"\"\"You are ChinookGPT, a helpful assistant who gets answers to user questions from the Chinook Music Database.\n",
    "Provide as many details as possible to your users\n",
    "Begin!\"\"\"\n",
    "\n",
    "sql_conversation = Conversation()\n",
    "sql_conversation.add_message(role=\"system\", content=agent_system_message)\n",
    "sql_conversation.add_message(\"user\", \"Hi, who are the top 5 artists by number of tracks\")\n",
    "assistant_message = chat_complete_execute_fn(\n",
    "    conversation=sql_conversation, functions=agentai_functions, model=GPT_MODEL, callable_function=ask_database\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "28471ddc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31msystem: You are ChinookGPT, a helpful assistant who gets answers to user questions from the Chinook Music Database.\n",
      "Provide as many details as possible to your users\n",
      "Begin!\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[32muser: Hi, who are the top 5 artists by number of tracks\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[35mfunction: [('Iron Maiden', 213), ('U2', 135), ('Led Zeppelin', 114), ('Metallica', 112), ('Lost', 92)]\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34massistant: The top 5 artists by number of tracks are:\n",
      "\n",
      "1. Iron Maiden - 213 tracks\n",
      "2. U2 - 135 tracks\n",
      "3. Led Zeppelin - 114 tracks\n",
      "4. Metallica - 112 tracks\n",
      "5. Lost - 92 tracks\n",
      "\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "sql_conversation.display_conversation(detailed=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "710481dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_conversation.add_message(\"user\", \"What is the name of the album with the most tracks\")\n",
    "chat_response = chat_complete_execute_fn(\n",
    "    conversation=sql_conversation, functions=agentai_functions, model=GPT_MODEL, callable_function=ask_database\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "13984dcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31msystem: You are ChinookGPT, a helpful assistant who gets answers to user questions from the Chinook Music Database.\n",
      "Provide as many details as possible to your users\n",
      "Begin!\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[32muser: Hi, who are the top 5 artists by number of tracks\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[35mfunction: [('Iron Maiden', 213), ('U2', 135), ('Led Zeppelin', 114), ('Metallica', 112), ('Lost', 92)]\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34massistant: The top 5 artists by number of tracks are:\n",
      "\n",
      "1. Iron Maiden - 213 tracks\n",
      "2. U2 - 135 tracks\n",
      "3. Led Zeppelin - 114 tracks\n",
      "4. Metallica - 112 tracks\n",
      "5. Lost - 92 tracks\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[32muser: What is the name of the album with the most tracks\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[35mfunction: [('Greatest Hits', 57)]\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34massistant: The album with the most tracks is \"Greatest Hits\" with 57 tracks.\n",
      "\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "sql_conversation.display_conversation(detailed=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
