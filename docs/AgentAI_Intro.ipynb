{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3e67f200",
   "metadata": {},
   "source": [
    "# AgentAI Introduction\n",
    "\n",
    "This library provides a simple, familiar and flexible way to combine Python functions with OpenAI functions. AgentAI builds on top of the OpenAI API, offering utilities to make it easier to manage conversations and implement function calls guided by AI responses.\n",
    "\n",
    "## Introduction\n",
    "\n",
    "The `agentai` library enables you to maintain the state of a conversation, invoke the model for generating responses, and parse the model's responses to generate function arguments that adhere to a given function specification. It also allows you to manage function specifications and execute functions whose inputs are model-generated. In this guide, we'll walk you through the library's various functionalities and demonstrate how to utilize them effectively.\n",
    "\n",
    "## What to expect\n",
    "\n",
    "We'll start by introducing the basic concepts: \n",
    "1. Tool\n",
    "1. Conversation\n",
    "2. An Function Specification\n",
    "\n",
    "Then, we will create a real-world application where we integrate model-generated arguments into function executions, demonstrating the interaction between the model and a SQLite database.\n",
    "\n",
    "## What is a Tool Decorator? <a name=\"tool-decorator\"></a>\n",
    "\n",
    "A tool decorator from the `agentai` library is a Python decorator. OpenAI Functions are specified with the following fields:\n",
    "\n",
    "- **Name:** The name of the function.\n",
    "- **Description:** A description of what the function does. The model will use this to decide when to call the function.\n",
    "- **Parameters:** The parameters object contains all of the input fields the function requires. These inputs can be of the following types: String, Number, Boolean, Object, Null, AnyOf. Refer to the [API reference docs](https://platform.openai.com/docs/api-reference/chat) for details.\n",
    "- **Required:** Which of the parameters are required to make a query. The rest will be treated as optional.\n",
    "\n",
    "These are auto-generated from a Python function when annotated with a `@tool`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "31425d9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: agentai in /opt/homebrew/Caskroom/miniconda/base/envs/qt/lib/python3.8/site-packages (0.0.1)\n",
      "Requirement already satisfied: ruff<0.0.273,>=0.0.272 in /opt/homebrew/Caskroom/miniconda/base/envs/qt/lib/python3.8/site-packages (from agentai) (0.0.272)\n",
      "Requirement already satisfied: termcolor<3.0.0,>=2.3.0 in /opt/homebrew/Caskroom/miniconda/base/envs/qt/lib/python3.8/site-packages (from agentai) (2.3.0)\n",
      "Requirement already satisfied: isort<6.0.0,>=5.12.0 in /opt/homebrew/Caskroom/miniconda/base/envs/qt/lib/python3.8/site-packages (from agentai) (5.12.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.31.0 in /opt/homebrew/Caskroom/miniconda/base/envs/qt/lib/python3.8/site-packages (from agentai) (2.31.0)\n",
      "Requirement already satisfied: docstring-parser<0.16,>=0.15 in /opt/homebrew/Caskroom/miniconda/base/envs/qt/lib/python3.8/site-packages (from agentai) (0.15)\n",
      "Requirement already satisfied: tiktoken<0.5.0,>=0.4.0 in /opt/homebrew/Caskroom/miniconda/base/envs/qt/lib/python3.8/site-packages (from agentai) (0.4.0)\n",
      "Requirement already satisfied: pandas<3.0.0,>=2.0.2 in /opt/homebrew/Caskroom/miniconda/base/envs/qt/lib/python3.8/site-packages (from agentai) (2.0.2)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.2.2 in /opt/homebrew/Caskroom/miniconda/base/envs/qt/lib/python3.8/site-packages (from agentai) (8.2.2)\n",
      "Requirement already satisfied: openai<0.28.0,>=0.27.8 in /opt/homebrew/Caskroom/miniconda/base/envs/qt/lib/python3.8/site-packages (from agentai) (0.27.8)\n",
      "Requirement already satisfied: tqdm in /opt/homebrew/Caskroom/miniconda/base/envs/qt/lib/python3.8/site-packages (from openai<0.28.0,>=0.27.8->agentai) (4.65.0)\n",
      "Requirement already satisfied: aiohttp in /opt/homebrew/Caskroom/miniconda/base/envs/qt/lib/python3.8/site-packages (from openai<0.28.0,>=0.27.8->agentai) (3.8.4)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/homebrew/Caskroom/miniconda/base/envs/qt/lib/python3.8/site-packages (from pandas<3.0.0,>=2.0.2->agentai) (2023.3)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/homebrew/Caskroom/miniconda/base/envs/qt/lib/python3.8/site-packages (from pandas<3.0.0,>=2.0.2->agentai) (2023.3)\n",
      "Requirement already satisfied: numpy>=1.20.3 in /opt/homebrew/Caskroom/miniconda/base/envs/qt/lib/python3.8/site-packages (from pandas<3.0.0,>=2.0.2->agentai) (1.24.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/homebrew/Caskroom/miniconda/base/envs/qt/lib/python3.8/site-packages (from pandas<3.0.0,>=2.0.2->agentai) (2.8.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/homebrew/Caskroom/miniconda/base/envs/qt/lib/python3.8/site-packages (from requests<3.0.0,>=2.31.0->agentai) (2.0.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/homebrew/Caskroom/miniconda/base/envs/qt/lib/python3.8/site-packages (from requests<3.0.0,>=2.31.0->agentai) (2023.5.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/homebrew/Caskroom/miniconda/base/envs/qt/lib/python3.8/site-packages (from requests<3.0.0,>=2.31.0->agentai) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/homebrew/Caskroom/miniconda/base/envs/qt/lib/python3.8/site-packages (from requests<3.0.0,>=2.31.0->agentai) (3.1.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /opt/homebrew/Caskroom/miniconda/base/envs/qt/lib/python3.8/site-packages (from tiktoken<0.5.0,>=0.4.0->agentai) (2023.6.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/homebrew/Caskroom/miniconda/base/envs/qt/lib/python3.8/site-packages (from python-dateutil>=2.8.2->pandas<3.0.0,>=2.0.2->agentai) (1.16.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/homebrew/Caskroom/miniconda/base/envs/qt/lib/python3.8/site-packages (from aiohttp->openai<0.28.0,>=0.27.8->agentai) (1.3.3)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/homebrew/Caskroom/miniconda/base/envs/qt/lib/python3.8/site-packages (from aiohttp->openai<0.28.0,>=0.27.8->agentai) (4.0.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/homebrew/Caskroom/miniconda/base/envs/qt/lib/python3.8/site-packages (from aiohttp->openai<0.28.0,>=0.27.8->agentai) (23.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/homebrew/Caskroom/miniconda/base/envs/qt/lib/python3.8/site-packages (from aiohttp->openai<0.28.0,>=0.27.8->agentai) (6.0.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/homebrew/Caskroom/miniconda/base/envs/qt/lib/python3.8/site-packages (from aiohttp->openai<0.28.0,>=0.27.8->agentai) (1.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/homebrew/Caskroom/miniconda/base/envs/qt/lib/python3.8/site-packages (from aiohttp->openai<0.28.0,>=0.27.8->agentai) (1.9.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install agentai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dab872c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown, Latex\n",
    "import json\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "GPT_MODEL = \"gpt-3.5-turbo-0613\"\n",
    "EMBEDDING_MODEL = \"text-embedding-ada-002\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "69ee6a93",
   "metadata": {},
   "source": [
    "## Utilities\n",
    "\n",
    "First let's import a few utilities for making calls to the Chat Completions API and for maintaining and keeping track of the conversation state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "745ceec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from agentai.api import chat_complete\n",
    "from agentai.openai_function import tool, FunctionRegistry\n",
    "from agentai.conversation import Conversation\n",
    "\n",
    "weather_registry = FunctionRegistry()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "29d4e02b",
   "metadata": {},
   "source": [
    "## Basic concepts\n",
    "\n",
    "Next we'll create a specification for a function called ```get_current_weather```. Later we'll pass this function specification to the API in order to generate function arguments that adhere to the specification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d2e25069",
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "\n",
    "\n",
    "class TemperatureUnit(Enum):\n",
    "    celsius = \"celsius\"\n",
    "    fahrenheit = \"fahrenheit\"\n",
    "\n",
    "\n",
    "@tool(weather_registry)\n",
    "def get_current_weather(location: str, format: TemperatureUnit) -> str:\n",
    "    \"\"\"\n",
    "    Get the current weather\n",
    "\n",
    "    Args:\n",
    "        location (str): The city and state, e.g. San Francisco, CA\n",
    "        format (str): The temperature unit to use. Infer this from the users location.\n",
    "\n",
    "    Returns:\n",
    "        str: The current weather\n",
    "    \"\"\"\n",
    "    # Your function implementation goes here.\n",
    "    return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "131d9a33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'role': 'assistant', 'content': 'Where are you currently located?'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation = Conversation()\n",
    "conversation.add_message(\"user\", \"what is the weather like today?\")\n",
    "\n",
    "message = {\"role\": \"assistant\", \"content\": None}\n",
    "chat_response = chat_complete(conversation.conversation_history, function_registry=weather_registry, model=GPT_MODEL)\n",
    "message = chat_response.json()[\"choices\"][0][\"message\"]\n",
    "while message[\"content\"] is None:\n",
    "    print(\"No response from assistant, trying again\")\n",
    "    chat_response = chat_complete(conversation.conversation_history, function_registry=weather_registry, model=GPT_MODEL)\n",
    "    message = chat_response.json()[\"choices\"][0][\"message\"]\n",
    "conversation.add_message(message[\"role\"], message[\"content\"])\n",
    "message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ee28e0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'user', 'content': 'what is the weather like today?'},\n",
       " {'role': 'assistant', 'content': 'Where are you currently located?'}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.conversation_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "854b6e61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'location': 'Bengaluru, India', 'format': 'celsius'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Once the user provides the required information, the model can generate the function arguments\n",
    "conversation.add_message(\"user\", \"I'm in Bengaluru, India\")\n",
    "chat_response = chat_complete(conversation.conversation_history, function_registry=weather_registry, model=GPT_MODEL)\n",
    "\n",
    "eval(chat_response.json()[\"choices\"][0][\"message\"][\"function_call\"][\"arguments\"])\n",
    "# chat_response.json()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b4482aee",
   "metadata": {},
   "source": [
    "## Integrating API calls with function execution\n",
    "\n",
    "In our next example, we'll demonstrate how to execute functions whose inputs are model-generated, and use this to implement an agent that can answer questions for us about a database. For simplicity we'll use the [Chinook sample database](https://www.sqlitetutorial.net/sqlite-sample-database/).\n",
    "\n",
    "*Note:* SQL generation use cases are high-risk in a production environment - models can be unreliable when generating consistent SQL syntax. A more reliable way to solve this problem may be to build a query generation API that takes the desired columns as input from the model."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f7654fef",
   "metadata": {},
   "source": [
    "### Pull SQL Database Info\n",
    "\n",
    "First let's define some helpful utility functions to extract data from a SQLite database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "30f6b60e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opened database successfully\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "\n",
    "conn = sqlite3.connect(\"../data/Chinook.db\")\n",
    "print(\"Opened database successfully\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "77e6e5ea",
   "metadata": {},
   "source": [
    "Now can use these utility functions to extract a representation of the database schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0c0104cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from agentai.sqlite_utils import DBUtils\n",
    "\n",
    "database_schema_dict = DBUtils(conn).get_database_info()\n",
    "database_schema_string = \"\\n\".join(\n",
    "    [f\"Table: {table['table_name']}\\nColumns: {', '.join(table['column_names'])}\" for table in database_schema_dict]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1f05b9e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table: Album\n",
      "Columns: AlbumId, Title, ArtistId\n",
      "Table: Artist\n",
      "Columns: ArtistId, Name\n",
      "Table: Customer\n",
      "Columns: CustomerId, FirstName, LastName, Company, Address, City, State, Country, PostalCode, Phone, Fax, Email, SupportRepId\n",
      "Table: Employee\n",
      "Columns: EmployeeId, LastName, FirstName, Title, ReportsTo, BirthDate, HireDate, Address, City, State, Country, PostalCode, Phone, Fax, Email\n",
      "Table: Genre\n",
      "Columns: GenreId, Name\n",
      "Table: Invoice\n",
      "Columns: InvoiceId, CustomerId, InvoiceDate, BillingAddress, BillingCity, BillingState, BillingCountry, BillingPostalCode, Total\n",
      "Table: InvoiceLine\n",
      "Columns: InvoiceLineId, InvoiceId, TrackId, UnitPrice, Quantity\n",
      "Table: MediaType\n",
      "Columns: MediaTypeId, Name\n",
      "Table: Playlist\n",
      "Columns: PlaylistId, Name\n",
      "Table: PlaylistTrack\n",
      "Columns: PlaylistId, TrackId\n",
      "Table: Track\n",
      "Columns: TrackId, Name, AlbumId, MediaTypeId, GenreId, Composer, Milliseconds, Bytes, UnitPrice\n"
     ]
    }
   ],
   "source": [
    "print(database_schema_string)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ae73c9ee",
   "metadata": {},
   "source": [
    "As before, we'll define a function specification for the function we'd like the API to generate arguments for. Notice that we are inserting the database schema into the function specification. This will be important for the model to know about."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0258813a",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def ask_database(query: str) -> str:\n",
    "    \"\"\"\n",
    "    Use this function to answer user questions about music. Input should be a fully formed SQL query.\n",
    "\n",
    "    Args:\n",
    "        query (str):SQL query extracting info to answer the user's question.\n",
    "                    SQL should be written using this database schema:\n",
    "                    Table: Album\n",
    "                    Columns: AlbumId, Title, ArtistId\n",
    "                    Table: Artist\n",
    "                    Columns: ArtistId, Name\n",
    "                    Table: Customer\n",
    "                    Columns: CustomerId, FirstName, LastName, Company, Address, City, State, Country, PostalCode, Phone, Fax, Email, SupportRepId\n",
    "                    Table: Employee\n",
    "                    Columns: EmployeeId, LastName, FirstName, Title, ReportsTo, BirthDate, HireDate, Address, City, State, Country, PostalCode, Phone, Fax, Email\n",
    "                    Table: Genre\n",
    "                    Columns: GenreId, Name\n",
    "                    Table: Invoice\n",
    "                    Columns: InvoiceId, CustomerId, InvoiceDate, BillingAddress, BillingCity, BillingState, BillingCountry, BillingPostalCode, Total\n",
    "                    Table: InvoiceLine\n",
    "                    Columns: InvoiceLineId, InvoiceId, TrackId, UnitPrice, Quantity\n",
    "                    Table: MediaType\n",
    "                    Columns: MediaTypeId, Name\n",
    "                    Table: Playlist\n",
    "                    Columns: PlaylistId, Name\n",
    "                    Table: PlaylistTrack\n",
    "                    Columns: PlaylistId, TrackId\n",
    "                    Table: Track\n",
    "                    Columns: TrackId, Name, AlbumId, MediaTypeId, GenreId, Composer, Milliseconds, Bytes, UnitPrice\n",
    "\n",
    "                    IMPORTANT: Please return a fixed SQL in PLAIN TEXT.\n",
    "                    Your response should consist of ONLY the SQL query.\n",
    "\n",
    "    Returns:\n",
    "        str: _description_\n",
    "    \"\"\"\n",
    "    try:\n",
    "        results = conn.execute(query).fetchall()\n",
    "        return results\n",
    "    except Exception as e:\n",
    "        raise Exception(f\"SQL error: {e}\")\n",
    "\n",
    "\n",
    "agentai_functions = [json.loads(func.json_info) for func in [ask_database]]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "da08c121",
   "metadata": {},
   "source": [
    "### SQL execution\n",
    "\n",
    "Now let's implement the function that the agent will use to query the database. We also need to implement utilities to integrate the calls to the Chat Completions API with the function it is calling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5f845a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "from agentai.api import chat_complete_execute_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "38c55083",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_system_message = \"\"\"You are ChinookGPT, a helpful assistant who gets answers to user questions from the Chinook Music Database.\n",
    "Provide as many details as possible to your users\n",
    "Begin!\"\"\"\n",
    "\n",
    "sql_conversation = Conversation()\n",
    "sql_conversation.add_message(role=\"system\", content=agent_system_message)\n",
    "sql_conversation.add_message(\"user\", \"Hi, who are the top 5 artists by number of tracks\")\n",
    "assistant_message = chat_complete_execute_fn(\n",
    "    conversation=sql_conversation, functions=agentai_functions, model=GPT_MODEL, callable_function=ask_database\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "28471ddc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31msystem: You are ChinookGPT, a helpful assistant who gets answers to user questions from the Chinook Music Database.\n",
      "Provide as many details as possible to your users\n",
      "Begin!\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[32muser: Hi, who are the top 5 artists by number of tracks\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[35mfunction: [('Iron Maiden', 213), ('U2', 135), ('Led Zeppelin', 114), ('Metallica', 112), ('Lost', 92)]\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34massistant: The top 5 artists by the number of tracks are:\n",
      "\n",
      "1. Iron Maiden - 213 tracks\n",
      "2. U2 - 135 tracks\n",
      "3. Led Zeppelin - 114 tracks\n",
      "4. Metallica - 112 tracks\n",
      "5. Lost - 92 tracks\n",
      "\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "sql_conversation.display_conversation(detailed=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "710481dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_conversation.add_message(\"user\", \"What is the name of the album with the most tracks\")\n",
    "chat_response = chat_complete_execute_fn(\n",
    "    conversation=sql_conversation, functions=agentai_functions, model=GPT_MODEL, callable_function=ask_database\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "13984dcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31msystem: You are ChinookGPT, a helpful assistant who gets answers to user questions from the Chinook Music Database.\n",
      "Provide as many details as possible to your users\n",
      "Begin!\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[32muser: Hi, who are the top 5 artists by number of tracks\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[35mfunction: [('Iron Maiden', 213), ('U2', 135), ('Led Zeppelin', 114), ('Metallica', 112), ('Lost', 92)]\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34massistant: The top 5 artists by the number of tracks are:\n",
      "\n",
      "1. Iron Maiden - 213 tracks\n",
      "2. U2 - 135 tracks\n",
      "3. Led Zeppelin - 114 tracks\n",
      "4. Metallica - 112 tracks\n",
      "5. Lost - 92 tracks\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[32muser: What is the name of the album with the most tracks\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[35mfunction: [('Greatest Hits', 57)]\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34massistant: The album with the most tracks is \"Greatest Hits\" with 57 tracks.\n",
      "\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "sql_conversation.display_conversation(detailed=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
