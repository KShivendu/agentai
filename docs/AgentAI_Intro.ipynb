{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3e67f200",
   "metadata": {},
   "source": [
    "# Magic Tools Introduction\n",
    "\n",
    "This library provides a simple, familiar and flexible way to combine Python functions with OpenAI functions. Magic Tools wraps the OpenAI API - making it easier to manage conversations and add AI to your Python applications.\n",
    "\n",
    "## Introduction\n",
    "\n",
    "The `magic_tools` library enables you to maintain the state of a conversation, invoke the model for generating responses, and parse the model's responses to generate function arguments that adhere to a given function specification. It also allows you to manage function specifications and execute functions whose inputs are model-generated. In this guide, we'll walk you through the library's various functionalities and demonstrate how to utilize them effectively.\n",
    "\n",
    "## What to expect\n",
    "\n",
    "We'll start by introducing the basic concepts: \n",
    "1. Tool\n",
    "1. Conversation\n",
    "2. An Function Specification\n",
    "\n",
    "Then, we will create a real-world application where we integrate model-generated arguments into function executions, demonstrating the interaction between the model and a SQLite database.\n",
    "\n",
    "## What is a Tool Decorator? <a name=\"tool-decorator\"></a>\n",
    "\n",
    "A tool decorator from the `magic_tools` library is a Python decorator. OpenAI Functions are specified with the following fields:\n",
    "\n",
    "- **Name:** The name of the function.\n",
    "- **Description:** A description of what the function does. The model will use this to decide when to call the function.\n",
    "- **Parameters:** The parameters object contains all of the input fields the function requires. These inputs can be of the following types: String, Number, Boolean, Object, Null, AnyOf. Refer to the [API reference docs](https://platform.openai.com/docs/api-reference/chat) for details.\n",
    "- **Required:** Which of the parameters are required to make a query. The rest will be treated as optional.\n",
    "\n",
    "These are auto-generated from a Python function when annotated with a `@tool`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "31425d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install agentai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dab872c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "GPT_MODEL = \"gpt-3.5-turbo-0613\"\n",
    "EMBEDDING_MODEL = \"text-embedding-ada-002\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "69ee6a93",
   "metadata": {},
   "source": [
    "## Utilities\n",
    "\n",
    "First let's import a few utilities for making calls to the Chat Completions API and for maintaining and keeping track of the conversation state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "745ceec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from agentai.api import chat_complete, chat_complete_execute_fn\n",
    "from agentai.openai_function import tool, ToolRegistry\n",
    "from agentai.conversation import Conversation\n",
    "from agentai.sqlite_utils import DBUtils\n",
    "\n",
    "from typing import Any\n",
    "from enum import Enum\n",
    "import sqlite3\n",
    "\n",
    "\n",
    "weather_registry = ToolRegistry()  # Namespace for functions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "29d4e02b",
   "metadata": {},
   "source": [
    "## Basic concepts\n",
    "\n",
    "Next we'll create a specification for a function called ```get_current_weather```. Later we'll pass this function specification to the API in order to generate function arguments that adhere to the specification.\n",
    "\n",
    "### Tool\n",
    "\n",
    "`@tool` is a magic decorator that wraps a Python function and generates a function specification using the function's docstring and type hints. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d2e25069",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TemperatureUnit(Enum):\n",
    "    celsius = \"celsius\"\n",
    "    fahrenheit = \"fahrenheit\"\n",
    "\n",
    "\n",
    "@tool(weather_registry)\n",
    "def get_current_weather(location: str, format: TemperatureUnit) -> str:\n",
    "    \"\"\"\n",
    "    Get the current weather\n",
    "\n",
    "    Args:\n",
    "        location (str): The city and state, e.g. San Francisco, CA\n",
    "        format (str): The temperature unit to use. Infer this from the users location.\n",
    "\n",
    "    Returns:\n",
    "        str: The current weather\n",
    "    \"\"\"\n",
    "    # Your function implementation goes here.\n",
    "    return \"\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3acf660f",
   "metadata": {},
   "source": [
    "### Conversation\n",
    "\n",
    "Conversation is a class that maintains the state of a conversation. It is used to keep track of the conversation history. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "131d9a33",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-06-15 19:35:34.292\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36magentai.api\u001b[0m:\u001b[36mchat_complete\u001b[0m:\u001b[36m49\u001b[0m - \u001b[1mOpenAI API returned: {\n",
      "  \"role\": \"assistant\",\n",
      "  \"content\": \"Sure, I can help you with that. Could you please provide me with the location?\"\n",
      "}\u001b[0m\n",
      "\u001b[32m2023-06-15 19:35:34.294\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36magentai.api\u001b[0m:\u001b[36mchat_complete\u001b[0m:\u001b[36m60\u001b[0m - \u001b[1mGot Message: {\n",
      "  \"id\": \"chatcmpl-7RhtN0s4VzKpF193RWuHjjaWdZeSJ\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"created\": 1686837933,\n",
      "  \"model\": \"gpt-3.5-turbo-0613\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"index\": 0,\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"Sure, I can help you with that. Could you please provide me with the location?\"\n",
      "      },\n",
      "      \"finish_reason\": \"stop\"\n",
      "    }\n",
      "  ],\n",
      "  \"usage\": {\n",
      "    \"prompt_tokens\": 154,\n",
      "    \"completion_tokens\": 19,\n",
      "    \"total_tokens\": 173\n",
      "  }\n",
      "}\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<OpenAIObject at 0x128719630> JSON: {\n",
       "  \"role\": \"assistant\",\n",
       "  \"content\": \"Sure, I can help you with that. Could you please provide me with the location?\"\n",
       "}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation = Conversation()\n",
    "conversation.add_message(\n",
    "    role=\"system\",\n",
    "    content=\"\"\"You are an AI assistant.\n",
    "- Follow the user's requirements carefully & to the letter.\n",
    "- First think step-by-step - describe your plan for what to do, written out in great detail.\n",
    "- Ask the user for any missing information.\n",
    "- Then decide about functions to use.\n",
    "- Minimize any other statements.\"\"\",\n",
    ")\n",
    "\n",
    "conversation.add_message(\"user\", \"what is the weather like today?\")\n",
    "\n",
    "chat_response = chat_complete(\n",
    "    conversation=conversation,\n",
    "    tool_registry=weather_registry,\n",
    "    model=GPT_MODEL,\n",
    "    return_function_params=False,\n",
    ")\n",
    "message = chat_response[\"choices\"][0][\"message\"]  # Get the first message\n",
    "conversation.add_message(message[\"role\"], message[\"content\"])\n",
    "message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "854b6e61",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-06-15 19:35:36.511\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36magentai.api\u001b[0m:\u001b[36mchat_complete\u001b[0m:\u001b[36m49\u001b[0m - \u001b[1mOpenAI API returned: {\n",
      "  \"role\": \"assistant\",\n",
      "  \"content\": null,\n",
      "  \"function_call\": {\n",
      "    \"name\": \"get_current_weather\",\n",
      "    \"arguments\": \"{\\n  \\\"location\\\": \\\"Bengaluru, India\\\",\\n  \\\"format\\\": \\\"celsius\\\"\\n}\"\n",
      "  }\n",
      "}\u001b[0m\n",
      "\u001b[32m2023-06-15 19:35:36.512\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36magentai.api\u001b[0m:\u001b[36mchat_complete\u001b[0m:\u001b[36m54\u001b[0m - \u001b[1mGot Function Call: {\n",
      "  \"id\": \"chatcmpl-7RhtPsYKOrbIfvO2AZ0jjFGC7zbPu\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"created\": 1686837935,\n",
      "  \"model\": \"gpt-3.5-turbo-0613\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"index\": 0,\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": null,\n",
      "        \"function_call\": {\n",
      "          \"name\": \"get_current_weather\",\n",
      "          \"arguments\": \"{\\n  \\\"location\\\": \\\"Bengaluru, India\\\",\\n  \\\"format\\\": \\\"celsius\\\"\\n}\"\n",
      "        }\n",
      "      },\n",
      "      \"finish_reason\": \"function_call\"\n",
      "    }\n",
      "  ],\n",
      "  \"usage\": {\n",
      "    \"prompt_tokens\": 187,\n",
      "    \"completion_tokens\": 29,\n",
      "    \"total_tokens\": 216\n",
      "  }\n",
      "}\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Once the user provides the required information, the model can generate the function arguments\n",
    "conversation.add_message(\"user\", \"I'm in Bengaluru, India\")\n",
    "chat_response = chat_complete(\n",
    "    conversation=conversation,\n",
    "    tool_registry=weather_registry,\n",
    "    model=GPT_MODEL,\n",
    "    return_function_params=True,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b4482aee",
   "metadata": {},
   "source": [
    "## Integrating API calls with function execution\n",
    "\n",
    "In our next example, we'll demonstrate how to execute functions whose inputs are model-generated, and use this to implement an agent that can answer questions for us about a database. For simplicity we'll use the [Chinook sample database](https://www.sqlitetutorial.net/sqlite-sample-database/).\n",
    "\n",
    "*Note:* SQL generation use cases are high-risk in a production environment - models can be unreliable when generating consistent SQL syntax. A more reliable way to solve this problem may be to build a query generation API that takes the desired columns as input from the model."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f7654fef",
   "metadata": {},
   "source": [
    "### Pull SQL Database Info\n",
    "\n",
    "First let's define some helpful utility functions to extract data from a SQLite database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "30f6b60e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opened database successfully\n"
     ]
    }
   ],
   "source": [
    "conn = sqlite3.connect(\"../data/Chinook.db\")\n",
    "print(\"Opened database successfully\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "77e6e5ea",
   "metadata": {},
   "source": [
    "Now can use these utility functions to extract a representation of the database schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0c0104cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table: Album\n",
      "Columns: AlbumId, Title, ArtistId\n",
      "Table: Artist\n",
      "Columns: ArtistId, Name\n",
      "Table: Customer\n",
      "Columns: CustomerId, FirstName, LastName, Company, Address, City, State, Country, PostalCode, Phone, Fax, Email, SupportRepId\n",
      "Table: Employee\n",
      "Columns: EmployeeId, LastName, FirstName, Title, ReportsTo, BirthDate, HireDate, Address, City, State, Country, PostalCode, Phone, Fax, Email\n",
      "Table: Genre\n",
      "Columns: GenreId, Name\n",
      "Table: Invoice\n",
      "Columns: InvoiceId, CustomerId, InvoiceDate, BillingAddress, BillingCity, BillingState, BillingCountry, BillingPostalCode, Total\n",
      "Table: InvoiceLine\n",
      "Columns: InvoiceLineId, InvoiceId, TrackId, UnitPrice, Quantity\n",
      "Table: MediaType\n",
      "Columns: MediaTypeId, Name\n",
      "Table: Playlist\n",
      "Columns: PlaylistId, Name\n",
      "Table: PlaylistTrack\n",
      "Columns: PlaylistId, TrackId\n",
      "Table: Track\n",
      "Columns: TrackId, Name, AlbumId, MediaTypeId, GenreId, Composer, Milliseconds, Bytes, UnitPrice\n"
     ]
    }
   ],
   "source": [
    "db_registry = ToolRegistry()  # Namespace for functions\n",
    "database_string = DBUtils(conn).get_database_string()\n",
    "print(database_string)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ae73c9ee",
   "metadata": {},
   "source": [
    "As before, we'll define a function specification for the function we'd like the API to generate arguments for. Notice that we are inserting the database schema into the function specification. This will be important for the model to know about."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0258813a",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool(registry=db_registry)\n",
    "def ask_database(query: str) -> Any:\n",
    "    \"\"\"\n",
    "    Use this function to answer user questions about music. Input should be a fully formed SQL query.\n",
    "\n",
    "    Args:\n",
    "        query (str):SQL query extracting info to answer the user's question.\n",
    "                    SQL should be written using this database schema:\n",
    "                    Table: Album\n",
    "                    Columns: AlbumId, Title, ArtistId\n",
    "                    Table: Artist\n",
    "                    Columns: ArtistId, Name\n",
    "                    Table: Customer\n",
    "                    Columns: CustomerId, FirstName, LastName, Company, Address, City, State, Country, PostalCode, Phone, Fax, Email, SupportRepId\n",
    "                    Table: Employee\n",
    "                    Columns: EmployeeId, LastName, FirstName, Title, ReportsTo, BirthDate, HireDate, Address, City, State, Country, PostalCode, Phone, Fax, Email\n",
    "                    Table: Genre\n",
    "                    Columns: GenreId, Name\n",
    "                    Table: Invoice\n",
    "                    Columns: InvoiceId, CustomerId, InvoiceDate, BillingAddress, BillingCity, BillingState, BillingCountry, BillingPostalCode, Total\n",
    "                    Table: InvoiceLine\n",
    "                    Columns: InvoiceLineId, InvoiceId, TrackId, UnitPrice, Quantity\n",
    "                    Table: MediaType\n",
    "                    Columns: MediaTypeId, Name\n",
    "                    Table: Playlist\n",
    "                    Columns: PlaylistId, Name\n",
    "                    Table: PlaylistTrack\n",
    "                    Columns: PlaylistId, TrackId\n",
    "                    Table: Track\n",
    "                    Columns: TrackId, Name, AlbumId, MediaTypeId, GenreId, Composer, Milliseconds, Bytes, UnitPrice\n",
    "\n",
    "                    IMPORTANT: Please return a fixed SQL in PLAIN TEXT.\n",
    "                    Your response should consist of ONLY the SQL query.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        results = conn.execute(query).fetchall()\n",
    "        return results\n",
    "    except Exception as e:\n",
    "        raise Exception(f\"SQL error: {e}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "da08c121",
   "metadata": {},
   "source": [
    "### SQL Execution\n",
    "\n",
    "Now let's implement the function that the agent will use to query the database. We also need to implement utilities to integrate the calls to the Chat Completions API with the function it is calling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "38c55083",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-06-15 19:39:46.473\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36magentai.api\u001b[0m:\u001b[36mchat_complete\u001b[0m:\u001b[36m44\u001b[0m - \u001b[1mOpenAI API returned: {\n",
      "  \"role\": \"assistant\",\n",
      "  \"content\": null,\n",
      "  \"function_call\": {\n",
      "    \"name\": \"ask_database\",\n",
      "    \"arguments\": \"{\\n  \\\"query\\\": \\\"SELECT Artist.Name, COUNT(*) AS TrackCount FROM Artist JOIN Album ON Artist.ArtistId = Album.ArtistId JOIN Track ON Album.AlbumId = Track.AlbumId GROUP BY Artist.ArtistId ORDER BY TrackCount DESC LIMIT 5;\\\"\\n}\"\n",
      "  }\n",
      "}\u001b[0m\n",
      "\u001b[32m2023-06-15 19:39:46.473\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36magentai.api\u001b[0m:\u001b[36mchat_complete\u001b[0m:\u001b[36m49\u001b[0m - \u001b[1mGot Function Call: {\n",
      "  \"id\": \"chatcmpl-7RhxQkzMzo5AzxWH5OHRmsf28Uzx3\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"created\": 1686838184,\n",
      "  \"model\": \"gpt-3.5-turbo-0613\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"index\": 0,\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": null,\n",
      "        \"function_call\": {\n",
      "          \"name\": \"ask_database\",\n",
      "          \"arguments\": \"{\\n  \\\"query\\\": \\\"SELECT Artist.Name, COUNT(*) AS TrackCount FROM Artist JOIN Album ON Artist.ArtistId = Album.ArtistId JOIN Track ON Album.AlbumId = Track.AlbumId GROUP BY Artist.ArtistId ORDER BY TrackCount DESC LIMIT 5;\\\"\\n}\"\n",
      "        }\n",
      "      },\n",
      "      \"finish_reason\": \"function_call\"\n",
      "    }\n",
      "  ],\n",
      "  \"usage\": {\n",
      "    \"prompt_tokens\": 407,\n",
      "    \"completion_tokens\": 63,\n",
      "    \"total_tokens\": 470\n",
      "  }\n",
      "}\u001b[0m\n",
      "\u001b[32m2023-06-15 19:39:46.474\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36magentai.api\u001b[0m:\u001b[36mchat_complete_execute_fn\u001b[0m:\u001b[36m99\u001b[0m - \u001b[1mfunction_arguments: {'query': 'SELECT Artist.Name, COUNT(*) AS TrackCount FROM Artist JOIN Album ON Artist.ArtistId = Album.ArtistId JOIN Track ON Album.AlbumId = Track.AlbumId GROUP BY Artist.ArtistId ORDER BY TrackCount DESC LIMIT 5;'}\u001b[0m\n",
      "\u001b[32m2023-06-15 19:39:46.474\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36magentai.api\u001b[0m:\u001b[36mchat_complete_execute_fn\u001b[0m:\u001b[36m101\u001b[0m - \u001b[1mcallable_function: <function ask_database at 0x1282748b0>\u001b[0m\n",
      "\u001b[32m2023-06-15 19:39:46.476\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36magentai.api\u001b[0m:\u001b[36mchat_complete_execute_fn\u001b[0m:\u001b[36m103\u001b[0m - \u001b[1mValidated function arguments\u001b[0m\n",
      "\u001b[32m2023-06-15 19:39:46.477\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36magentai.api\u001b[0m:\u001b[36mchat_complete_execute_fn\u001b[0m:\u001b[36m105\u001b[0m - \u001b[1mresults: [('Iron Maiden', 213), ('U2', 135), ('Led Zeppelin', 114), ('Metallica', 112), ('Lost', 92)]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Iron Maiden', 213), ('U2', 135), ('Led Zeppelin', 114), ('Metallica', 112), ('Lost', 92)]\n"
     ]
    }
   ],
   "source": [
    "agent_system_message = \"\"\"You are ChinookGPT, a helpful assistant who gets answers to user questions from the Chinook Music Database.\n",
    "Provide as many details as possible to your users\n",
    "Begin!\"\"\"\n",
    "\n",
    "sql_conversation = Conversation()\n",
    "sql_conversation.add_message(role=\"system\", content=agent_system_message)\n",
    "sql_conversation.add_message(\n",
    "    role=\"user\", content=\"Hi, who are the top 5 artists by number of tracks\"\n",
    ")\n",
    "results, executed_function = chat_complete_execute_fn(\n",
    "    conversation=sql_conversation,\n",
    "    tool_registry=db_registry,\n",
    "    model=GPT_MODEL,\n",
    ")\n",
    "print(results)\n",
    "sql_conversation.add_message(role=\"assistant\", content=str(results), name=executed_function.__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "28471ddc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31msystem: You are ChinookGPT, a helpful assistant who gets answers to user questions from the Chinook Music Database.\n",
      "Provide as many details as possible to your users\n",
      "Begin!\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[32muser: Hi, who are the top 5 artists by number of tracks\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34massistant: [('Iron Maiden', 213), ('U2', 135), ('Led Zeppelin', 114), ('Metallica', 112), ('Lost', 92)]\n",
      "\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "sql_conversation.display_conversation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "710481dc",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "chat_complete_execute_fn() got an unexpected keyword argument 'function_registry'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m sql_conversation\u001b[39m.\u001b[39madd_message(\n\u001b[1;32m      2\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39muser\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mWhat is the name of the album with the most tracks\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m      3\u001b[0m )\n\u001b[0;32m----> 4\u001b[0m chat_response \u001b[39m=\u001b[39m chat_complete_execute_fn(\n\u001b[1;32m      5\u001b[0m     conversation\u001b[39m=\u001b[39;49msql_conversation,\n\u001b[1;32m      6\u001b[0m     function_registry\u001b[39m=\u001b[39;49mdb_registry,\n\u001b[1;32m      7\u001b[0m     model\u001b[39m=\u001b[39;49mGPT_MODEL,\n\u001b[1;32m      8\u001b[0m     callable_function\u001b[39m=\u001b[39;49mask_database,\n\u001b[1;32m      9\u001b[0m )\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/qt/lib/python3.8/site-packages/tenacity/__init__.py:289\u001b[0m, in \u001b[0;36mBaseRetrying.wraps.<locals>.wrapped_f\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(f)\n\u001b[1;32m    288\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped_f\u001b[39m(\u001b[39m*\u001b[39margs: t\u001b[39m.\u001b[39mAny, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkw: t\u001b[39m.\u001b[39mAny) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m t\u001b[39m.\u001b[39mAny:\n\u001b[0;32m--> 289\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m(f, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkw)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/qt/lib/python3.8/site-packages/tenacity/__init__.py:379\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    377\u001b[0m retry_state \u001b[39m=\u001b[39m RetryCallState(retry_object\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m, fn\u001b[39m=\u001b[39mfn, args\u001b[39m=\u001b[39margs, kwargs\u001b[39m=\u001b[39mkwargs)\n\u001b[1;32m    378\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 379\u001b[0m     do \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49miter(retry_state\u001b[39m=\u001b[39;49mretry_state)\n\u001b[1;32m    380\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(do, DoAttempt):\n\u001b[1;32m    381\u001b[0m         \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/qt/lib/python3.8/site-packages/tenacity/__init__.py:314\u001b[0m, in \u001b[0;36mBaseRetrying.iter\u001b[0;34m(self, retry_state)\u001b[0m\n\u001b[1;32m    312\u001b[0m is_explicit_retry \u001b[39m=\u001b[39m fut\u001b[39m.\u001b[39mfailed \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(fut\u001b[39m.\u001b[39mexception(), TryAgain)\n\u001b[1;32m    313\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (is_explicit_retry \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mretry(retry_state)):\n\u001b[0;32m--> 314\u001b[0m     \u001b[39mreturn\u001b[39;00m fut\u001b[39m.\u001b[39;49mresult()\n\u001b[1;32m    316\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mafter \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    317\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mafter(retry_state)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/qt/lib/python3.8/concurrent/futures/_base.py:437\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    435\u001b[0m     \u001b[39mraise\u001b[39;00m CancelledError()\n\u001b[1;32m    436\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39m==\u001b[39m FINISHED:\n\u001b[0;32m--> 437\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__get_result()\n\u001b[1;32m    439\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_condition\u001b[39m.\u001b[39mwait(timeout)\n\u001b[1;32m    441\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/qt/lib/python3.8/concurrent/futures/_base.py:389\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception:\n\u001b[1;32m    388\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 389\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception\n\u001b[1;32m    390\u001b[0m     \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    391\u001b[0m         \u001b[39m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[1;32m    392\u001b[0m         \u001b[39mself\u001b[39m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/qt/lib/python3.8/site-packages/tenacity/__init__.py:382\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    380\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(do, DoAttempt):\n\u001b[1;32m    381\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 382\u001b[0m         result \u001b[39m=\u001b[39m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    383\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m:  \u001b[39m# noqa: B902\u001b[39;00m\n\u001b[1;32m    384\u001b[0m         retry_state\u001b[39m.\u001b[39mset_exception(sys\u001b[39m.\u001b[39mexc_info())  \u001b[39m# type: ignore[arg-type]\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: chat_complete_execute_fn() got an unexpected keyword argument 'function_registry'"
     ]
    }
   ],
   "source": [
    "sql_conversation.add_message(\n",
    "    \"user\", \"What is the name of the album with the most tracks\"\n",
    ")\n",
    "chat_response = chat_complete_execute_fn(\n",
    "    conversation=sql_conversation,\n",
    "    tool_registry=db_registry,\n",
    "    model=GPT_MODEL,\n",
    "    callable_function=ask_database,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13984dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_conversation.display_conversation()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "690aa55b",
   "metadata": {},
   "source": [
    "# Using Multiple Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad61637",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "data_dir = Path(\"../data/papers\")\n",
    "data_dir.mkdir(exist_ok=True, parents=True)\n",
    "assert data_dir.exists()\n",
    "\n",
    "Path.ls = lambda x: list(x.iterdir())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affb6aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
